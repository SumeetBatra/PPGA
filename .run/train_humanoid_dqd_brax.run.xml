<component name="ProjectRunConfigurationManager">
  <configuration default="false" name="train_humanoid_dqd_brax" type="PythonConfigurationType" factoryName="Python">
    <module name="QDPPO" />
    <option name="INTERPRETER_OPTIONS" value="" />
    <option name="PARENT_ENVS" value="true" />
    <envs>
      <env name="PYTHONUNBUFFERED" value="1" />
      <env name="XLA_PYTHON_CLIENT_PREALLOCATE" value="false" />
    </envs>
    <option name="SDK_HOME" value="" />
    <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$/" />
    <option name="IS_MODULE_SDK" value="true" />
    <option name="ADD_CONTENT_ROOTS" value="true" />
    <option name="ADD_SOURCE_ROOTS" value="true" />
    <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
    <option name="SCRIPT_NAME" value="$PROJECT_DIR$/algorithm/train_qdppo.py" />
    <option name="PARAMETERS" value="--env_name=humanoid --rollout_length=128 --use_wandb=True --wandb_group=QDPPO --num_dims=2 --seed=1111 --anneal_lr=False --num_minibatches=8 --update_epochs=4 --normalize_obs=True --normalize_rewards=True --wandb_run_name=humanoid_debug_obs_norm --popsize=300 --env_batch_size=3000 --learning_rate=0.0003 --vf_coef=2 --entropy_coef=0.0 --target_kl=0.008 --max_grad_norm=1 --total_iterations=2000 --dqd_algorithm=cma_maega --sigma0=0.5 --restart_rule=no_improvement --calc_gradient_iters=10 --move_mean_iters=10 --archive_lr=0.1 --threshold_min=200 --grid_size=50 --logdir=./experiments/debug" />
    <option name="SHOW_COMMAND_LINE" value="false" />
    <option name="EMULATE_TERMINAL" value="false" />
    <option name="MODULE_MODE" value="false" />
    <option name="REDIRECT_INPUT" value="false" />
    <option name="INPUT_FILE" value="" />
    <method v="2" />
  </configuration>
</component>